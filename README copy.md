## Run PyTorch models in the browser using ONNX.js

Run PyTorch models in the browser with JavaScript by first converting your PyTorch model into the ONNX format and then loading that ONNX model in your website or app using ONNX.js. In the video tutorial below, I take you through this process using the demo example of a handwritten digit recognition model trained on the MNIST dataset.

jp: PyTorchモデルをONNX形式に変換し、ONNX.jsを使用してウェブサイトやアプリでそのONNXモデルをロードすることで、JavaScriptでブラウザでPyTorchモデルを実行します。以下のビデオチュートリアルでは、MNISTデータセットでトレーニングされた手書き数字認識モデルのデモ例を使用して、このプロセスを説明します。

### Tutorial
https://www.youtube.com/watch?v=Vs730jsRgO8

[<img src="https://img.youtube.com/vi/Vs730jsRgO8/hqdefault.jpg">](https://www.youtube.com/watch?v=Vs730jsRgO8)

### Live Demo and Code Sandbox

* [Live demo](https://vgzep.csb.app/)

* [Code sandbox](https://codesandbox.io/s/pytorch-to-javascript-with-onnx-vgzep)

Note: The model used in this demo is not very accurate, it will often
[misclassify digits](https://github.com/elliotwaite/pytorch-to-javascript-with-onnx-js/issues/1).

jp: このデモで使用されるモデルはあまり正確ではなく、しばしば数字を誤分類します。これは、証明のためにのみ使用されるものであり、[PyTorchのMNISTの例](

It's only meant to be used as a proof of concept. It's the same model that was
used in [PyTorch's MNIST example](https://github.com/pytorch/examples/blob/main/mnist/main.py).

jp: これは概念の証明としてのみ使用することを意図しています。これは、[PyTorchのMNISTの例]

You can find more accurate image classification models here: [Papers With Code -
Image Classification](https://paperswithcode.com/task/image-classification)

jp: より正確な画像分類モデルはこちらで見つけることができます: [Papers With Code - 画像分類](https://paperswithcode.com/task/image-classification)

### The files in this repo (and a description of what they do)
```
├── degug_demo
│   ├── debug.html (A debug test to make sure the generated ONNX model works. 
│   │               Uses ONNX.js to load and run the generated ONNX model.)
                    jp: 生成されたONNXモデルが機能することを確認するためのデバッグテスト。ONNX.jsを使用して生成されたONNXモデルをロードして実行します。
│   │ 
│   └── onnx_model.onnx (A copy of the generated ONNX model that will be loaded
│                        for debugging.)
                        jp: デバッグ用にロードされる生成されたONNXモデルのコピー。
│
├── full_demo
│   ├── index.html (The full demo's HTML code.)
│   │ 
│   ├── onnx_model.onnx (A copy of the generated ONNX model. Used by script.js.)
│   │ 
│   ├── script.js (The full demos's JS code. Loads the onnx_model.onnx and 
│   │              predicts the drawn numbers.)
│   │ 
│   └── style.css (The full demo's CSS.)
│                            
├── convert_to_onnx.py (Converts a trained PyTorch model into an ONNX model.)
│
├── inference_mnist_model.py (The PyTorch model description. Used by
│                             convert_to_onnx.py to generate the ONNX model.)
                            jp: PyTorchモデルの説明。ONNXモデルを生成するためにconvert_to_onnx.pyで使用されます。
│                             
├── inputs_batch_preview.png (A preview of a batch of augmented input data. 
│                             Generated by preview_mnist_dataset.py.)
                            jp: 拡張された入力データのバッチのプレビュー。preview_mnist_dataset.pyによって生成されます。
│
├── onnx_model.py (The ONNX model generated by convert_to_onnx.py.)
                    jp: convert_to_onnx.pyによって生成されたONNXモデル。
│
├── preview_dataset.py (For testing out different types of data augmentation.)
                        jp: 異なる種類のデータ拡張をテストするため。
│
├── pytorch_model.pt (The trained PyTorch model parameters. Generated by 
│                     train_mnist.model.py and used by convert_to_onnx.py to
│                     generate the ONNX model.)
                        jp: 訓練されたPyTorchモデルのパラメータ。train_mnist.model.pyによって生成され、convert_to_onnx.pyによってONNXモデルを生成するために使用されます。
│
└── train_mnist_model.pt (Trains the PyTorch model and saves the trained 
                          parameters as pytorch_model.pt.)
                          jp: PyTorchモデルをトレーニングし、訓練されたパラメータをpytorch_model.ptとして保存します。
```

### The benefits of running a model in the browser:

jp: ブラウザでモデルを実行する利点:

* Faster inference times with smaller models.
* Easy to host and scale (only static files).
* Offline support.
* User privacy (can keep the data on the device).

### The benefits of using a backend server:

* Faster load times (don't have to download the model).
* Faster and consistent inference times with larger models (can take advantage of GPUs or other accelerators).
* Model privacy (don't have to share your model if you want to keep it private).

## License

[MIT](LICENSE)

## mysetting

pyinit.sh

install_torch_cpu.sh

install_onnx.sh

## check

preview_dataset.pyによる画像変換はtrain_mnist_model.pyに入っていた。


## training log

### 1st try

train_mnist_model.py → pytorch_model.pt

default → 86 %

### 2nd try

change affine value settig

```python
                    transforms.RandomAffine(
                        degrees=15,
                        translate=(0.2, 0.2),
                        scale=(0.75, 1),
                        shear=(-15, 15, -15, 15),
                    ),
```

## make onnx_model

convert_to_onnx.py → onnx_model.onnx

## set opset_version

try default code , but now version is not support AveragePool

try opset_version=10, MaxPool is not support

so , try opset_version=9 , it's ok

convert_to_onnx.py

```python
    torch.onnx.export(
        pytorch_model, dummy_input, "onnx_model.onnx", verbose=True, opset_version=9
    )
```

version support table is here

https://github.com/microsoft/onnxjs/blob/master/docs/operators.md

